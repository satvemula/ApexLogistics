{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvemula/ApexLogistics/blob/main/Supply_Chain_Training_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNaIQjnTNiUI",
        "outputId": "9a8e2c38-3fc9-4fb5-a18d-5e9681842a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: mlflow-skinny==3.6.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.6.0)\n",
            "Requirement already satisfied: mlflow-tracing==3.6.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.6.0)\n",
            "Requirement already satisfied: Flask-CORS<7 in /usr/local/lib/python3.12/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.12/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: huey<3,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.5.4)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.73.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.118.3)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.38.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.7)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.43.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (2025.11.12)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.6.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1. Installation Cell\n",
        "# Install requested advanced models: LightGBM, XGBoost, CatBoost\n",
        "# ==============================================================================\n",
        "!pip install mlflow\n",
        "!pip install scikit-learn\n",
        "!pip install lightgbm xgboost catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. IMPORTS (Final Update)\n",
        "# Ensure all necessary libraries for preprocessing and modeling are imported.\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.exceptions import NotFittedError\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.decomposition import PCA # Kept for completeness, though not used in the final flow\n",
        "\n",
        "# Requested Scikit-learn Models (Classification)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# NEW: Missing Models\n",
        "from sklearn.svm import SVC # Support Vector Classifier\n",
        "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bayes\n",
        "from sklearn.neighbors import KNeighborsClassifier # k-Nearest Neighbors\n",
        "\n",
        "# Boosting Models\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# MLflow\n",
        "import mlflow\n",
        "import mlflow.sklearn"
      ],
      "metadata": {
        "id": "idIHfRdENtQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. CONFIGURE DATABRICKS MLFLOW TRACKING (FIXED)\n",
        "# ==============================================================================\n",
        "import os\n",
        "import mlflow\n",
        "# FIX: Import userdata to access secrets in Colab\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CONFIGURING DATABRICKS MLFLOW\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Define experiment path explicitly\n",
        "EXPERIMENT_NAME = \"/Users/svemulak@asu.edu/Attempt_6_Supply-Chain-Classification-Experiment-1\"\n",
        "\n",
        "try:\n",
        "    # Attempt to load secrets\n",
        "    DATABRICKS_HOST = userdata.get('DATABRICKS_HOST')\n",
        "    DATABRICKS_TOKEN = userdata.get('DATABRICKS_TOKEN')\n",
        "\n",
        "    os.environ[\"DATABRICKS_HOST\"] = DATABRICKS_HOST\n",
        "    os.environ[\"DATABRICKS_TOKEN\"] = DATABRICKS_TOKEN\n",
        "\n",
        "    mlflow.set_tracking_uri(\"databricks\")\n",
        "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "    print(f\"✓ Using Databricks experiment: {EXPERIMENT_NAME}\")\n",
        "    print(f\"✓ Databricks workspace: {DATABRICKS_HOST}\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"⚠ Error: 'userdata' not found. Ensure you are running in Colab and have imported it.\")\n",
        "    print(\"  Continuing with local MLflow tracking...\")\n",
        "    mlflow.set_tracking_uri(\"file:./mlruns\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Warning: Could not connect to Databricks: {e}\")\n",
        "    print(\"  Continuing with local MLflow tracking...\")\n",
        "    mlflow.set_tracking_uri(\"file:./mlruns\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKILaxcSNrK5",
        "outputId": "ff6b2b4f-b97a-4222-aad6-f6e7571c2472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CONFIGURING DATABRICKS MLFLOW\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/04 22:36:21 INFO mlflow.tracking.fluent: Experiment with name '/Users/svemulak@asu.edu/Attempt_6_Supply-Chain-Classification-Experiment-1' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Using Databricks experiment: /Users/svemulak@asu.edu/Attempt_6_Supply-Chain-Classification-Experiment-1\n",
            "✓ Databricks workspace: https://dbc-a0c89f71-7936.cloud.databricks.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. LOAD CSV FROM MY COMPUTER (KEPT UNCHANGED)\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LOADING DATASET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(uploaded[list(uploaded.keys())[0]]))\n",
        "\n",
        "print(f\"\\n✓ Dataset loaded successfully!\")\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"  Columns: {list(df.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "DVOrJoDLN2ef",
        "outputId": "02cbb928-47d5-44f3-8aa9-c25c569e3e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING DATASET\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da04c805-0148-4d1c-b2ec-801e194ce709\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da04c805-0148-4d1c-b2ec-801e194ce709\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving c2k_data_comma.csv to c2k_data_comma (6).csv\n",
            "\n",
            "✓ Dataset loaded successfully!\n",
            "  Shape: (3943, 98)\n",
            "  Columns: ['nr', 'i1_legid', 'i1_rcs_p', 'i1_rcs_e', 'i1_dep_1_p', 'i1_dep_1_e', 'i1_dep_1_place', 'i1_rcf_1_p', 'i1_rcf_1_e', 'i1_rcf_1_place', 'i1_dep_2_p', 'i1_dep_2_e', 'i1_dep_2_place', 'i1_rcf_2_p', 'i1_rcf_2_e', 'i1_rcf_2_place', 'i1_dep_3_p', 'i1_dep_3_e', 'i1_dep_3_place', 'i1_rcf_3_p', 'i1_rcf_3_e', 'i1_rcf_3_place', 'i1_dlv_p', 'i1_dlv_e', 'i1_hops', 'i2_legid', 'i2_rcs_p', 'i2_rcs_e', 'i2_dep_1_p', 'i2_dep_1_e', 'i2_dep_1_place', 'i2_rcf_1_p', 'i2_rcf_1_e', 'i2_rcf_1_place', 'i2_dep_2_p', 'i2_dep_2_e', 'i2_dep_2_place', 'i2_rcf_2_p', 'i2_rcf_2_e', 'i2_rcf_2_place', 'i2_dep_3_p', 'i2_dep_3_e', 'i2_dep_3_place', 'i2_rcf_3_p', 'i2_rcf_3_e', 'i2_rcf_3_place', 'i2_dlv_p', 'i2_dlv_e', 'i2_hops', 'i3_legid', 'i3_rcs_p', 'i3_rcs_e', 'i3_dep_1_p', 'i3_dep_1_e', 'i3_dep_1_place', 'i3_rcf_1_p', 'i3_rcf_1_e', 'i3_rcf_1_place', 'i3_dep_2_p', 'i3_dep_2_e', 'i3_dep_2_place', 'i3_rcf_2_p', 'i3_rcf_2_e', 'i3_rcf_2_place', 'i3_dep_3_p', 'i3_dep_3_e', 'i3_dep_3_place', 'i3_rcf_3_p', 'i3_rcf_3_e', 'i3_rcf_3_place', 'i3_dlv_p', 'i3_dlv_e', 'i3_hops', 'o_legid', 'o_rcs_p', 'o_rcs_e', 'o_dep_1_p', 'o_dep_1_e', 'o_dep_1_place', 'o_rcf_1_p', 'o_rcf_1_e', 'o_rcf_1_place', 'o_dep_2_p', 'o_dep_2_e', 'o_dep_2_place', 'o_rcf_2_p', 'o_rcf_2_e', 'o_rcf_2_place', 'o_dep_3_p', 'o_dep_3_e', 'o_dep_3_place', 'o_rcf_3_p', 'o_rcf_3_e', 'o_rcf_3_place', 'o_dlv_p', 'o_dlv_e', 'o_hops', 'legs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. PREPROCESSING (Final Corrected Code Block)\n",
        "# FIX APPLIED: Feature name cleanup added to resolve CatBoost/XGBoost errors.\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nOriginal dataset size: {df.shape[0]} rows\")\n",
        "\n",
        "# 1. Replace '?' and Drop 100% Missing Columns\n",
        "df = df.replace('?', np.nan)\n",
        "print(\"✓ Replaced '?' with NaN.\")\n",
        "\n",
        "df_cols_before = df.shape[1]\n",
        "df = df.dropna(axis=1, how='all')\n",
        "print(f\"✓ Dropped {df_cols_before - df.shape[1]} columns that were 100% NaN.\")\n",
        "\n",
        "# 2. Target Definition and Integrity Check\n",
        "TARGET_COLUMN = 'legs'\n",
        "\n",
        "if TARGET_COLUMN not in df.columns:\n",
        "    print(f\"\\n--- FATAL ERROR: Target column '{TARGET_COLUMN}' not found in the DataFrame. ---\")\n",
        "else:\n",
        "    # --- TARGET INTEGRITY FIX ---\n",
        "    initial_rows = len(df)\n",
        "    df = df.dropna(subset=[TARGET_COLUMN])\n",
        "    print(f\"✓ Dropped {initial_rows - len(df)} rows with missing target '{TARGET_COLUMN}'.\")\n",
        "    # --- END OF TARGET INTEGRITY FIX ---\n",
        "\n",
        "    # 3. Handle Categorical Columns and Encoding\n",
        "    label_encoders = {}\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "    if TARGET_COLUMN in categorical_cols:\n",
        "        categorical_cols.remove(TARGET_COLUMN)\n",
        "\n",
        "    print(f\"\\nEncoding {len(categorical_cols)} feature columns...\")\n",
        "    for col in categorical_cols:\n",
        "        df[col] = df[col].fillna('_IMPUTE_CATEGORY_')\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "        print(f\"  ✓ Encoded: {col}\")\n",
        "\n",
        "    # Encode the Target Column (y) separately\n",
        "    print(f\"\\nEncoding target column: {TARGET_COLUMN}\")\n",
        "    target_encoder = LabelEncoder()\n",
        "    df[TARGET_COLUMN] = df[TARGET_COLUMN].astype(int)\n",
        "    df[TARGET_COLUMN] = target_encoder.fit_transform(df[TARGET_COLUMN])\n",
        "    label_encoders[TARGET_COLUMN] = target_encoder\n",
        "    print(f\"  ✓ Encoded: {TARGET_COLUMN}\")\n",
        "\n",
        "    # 4. Final Split into X and y\n",
        "    X = df.drop(TARGET_COLUMN, axis=1)\n",
        "    y = df[TARGET_COLUMN]\n",
        "\n",
        "    # --- REVISED DATA LEAKAGE FIX ---\n",
        "    LEAKY_COLUMNS_PATTERNS = ['i1_hops', 'i2_hops', 'o_hops', 'nr', 'i2_dlv_p', 'i2_dlv_e']\n",
        "    i3_cols = [col for col in X.columns if col.startswith('i3_')]\n",
        "    LEAKY_COLUMNS_TO_DROP = set(LEAKY_COLUMNS_PATTERNS + i3_cols)\n",
        "\n",
        "    X = X.drop(columns=[col for col in LEAKY_COLUMNS_TO_DROP if col in X.columns], errors='ignore')\n",
        "    print(f\"\\nRemoved potential leaky columns: {LEAKY_COLUMNS_TO_DROP}\")\n",
        "    print(f\"New X shape after removing leak: {X.shape}\")\n",
        "    # --- END OF DATA LEAKAGE FIX ---\n",
        "\n",
        "    # 5. Impute Remaining NaNs (For numerical features)\n",
        "    print(\"\\nImputing remaining NaNs using median strategy...\")\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_imputed = imputer.fit_transform(X)\n",
        "    X = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
        "    print(\"  ✓ Imputation completed.\")\n",
        "\n",
        "    # 6. Feature Scaling (Crucial for Logistic Regression convergence)\n",
        "    print(\"\\nScaling numerical features...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
        "    print(\"  ✓ Scaling completed.\")\n",
        "    # --- END OF SCALING ---\n",
        "\n",
        "    # ==========================================================================\n",
        "    # 6.5 FEATURE ENGINEERING (Targeted Interaction Terms + Selection)\n",
        "    # ==========================================================================\n",
        "    print(\"\\nCreating 2nd-degree Polynomial/Interaction Features (Targeted)...\")\n",
        "\n",
        "    # 1. Generate ALL interaction features (temporarily creates ~4000 features)\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    poly_feature_names = poly.get_feature_names_out(X.columns)\n",
        "\n",
        "    # Create a DataFrame of just the new interaction terms\n",
        "    X_interaction_only = pd.DataFrame(X_poly, columns=poly_feature_names, index=X.index)\n",
        "\n",
        "    # 2. Select only the top 200 interaction features based on absolute correlation with the target\n",
        "    correlation = X_interaction_only.apply(lambda col: np.abs(col.corr(y)))\n",
        "    top_interaction_features = correlation.nlargest(200).index\n",
        "\n",
        "    # 3. Update X to include only the original features plus the top 200 selected interaction features\n",
        "    X = pd.concat([X, X_interaction_only[top_interaction_features]], axis=1)\n",
        "\n",
        "    print(f\"  ✓ Added top 200 interaction features.\")\n",
        "\n",
        "    # ==========================================================================\n",
        "    # 6.6 FINAL FEATURE CLEANUP (Fixes Boosting Model Errors)\n",
        "    # ==========================================================================\n",
        "    print(\"\\nCleaning up feature names for model compatibility...\")\n",
        "\n",
        "    # 1. Remove duplicate columns (required for CatBoost/LightGBM fix)\n",
        "    X = X.loc[:,~X.columns.duplicated()]\n",
        "\n",
        "    # 2. Rename columns to simple strings (required for XGBoost fix)\n",
        "    X.columns = [f'f_{i}' for i in range(X.shape[1])]\n",
        "\n",
        "    print(f\"  ✓ Cleanup completed. Final unique feature count: {X.shape[1]}\")\n",
        "    # ==========================================================================\n",
        "\n",
        "    print(f\"\\nTarget variable distribution (Encoded):\")\n",
        "    print(y.value_counts())\n",
        "\n",
        "    # 7. Train/Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"\\n✓ Train/test split completed:\")\n",
        "    print(f\"  X_train shape: {X_train.shape}\")\n",
        "    print(f\"  X_test shape: {X_test.shape}\")\n",
        "    print(f\"  y_train shape: {y_train.shape}\")\n",
        "    print(f\"  y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5O3Mir-N9wP",
        "outputId": "087f6ada-9d56-48c4-a4ea-13772ec2a68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATA PREPROCESSING\n",
            "======================================================================\n",
            "\n",
            "Original dataset size: 3943 rows\n",
            "✓ Replaced '?' with NaN.\n",
            "✓ Dropped 0 columns that were 100% NaN.\n",
            "✓ Dropped 1 rows with missing target 'legs'.\n",
            "\n",
            "Encoding 72 feature columns...\n",
            "  ✓ Encoded: i1_dep_2_p\n",
            "  ✓ Encoded: i1_dep_2_e\n",
            "  ✓ Encoded: i1_dep_2_place\n",
            "  ✓ Encoded: i1_rcf_2_p\n",
            "  ✓ Encoded: i1_rcf_2_e\n",
            "  ✓ Encoded: i1_rcf_2_place\n",
            "  ✓ Encoded: i1_dep_3_p\n",
            "  ✓ Encoded: i1_dep_3_e\n",
            "  ✓ Encoded: i1_dep_3_place\n",
            "  ✓ Encoded: i1_rcf_3_p\n",
            "  ✓ Encoded: i1_rcf_3_e\n",
            "  ✓ Encoded: i1_rcf_3_place\n",
            "  ✓ Encoded: i2_legid\n",
            "  ✓ Encoded: i2_rcs_p\n",
            "  ✓ Encoded: i2_rcs_e\n",
            "  ✓ Encoded: i2_dep_1_p\n",
            "  ✓ Encoded: i2_dep_1_e\n",
            "  ✓ Encoded: i2_dep_1_place\n",
            "  ✓ Encoded: i2_rcf_1_p\n",
            "  ✓ Encoded: i2_rcf_1_e\n",
            "  ✓ Encoded: i2_rcf_1_place\n",
            "  ✓ Encoded: i2_dep_2_p\n",
            "  ✓ Encoded: i2_dep_2_e\n",
            "  ✓ Encoded: i2_dep_2_place\n",
            "  ✓ Encoded: i2_rcf_2_p\n",
            "  ✓ Encoded: i2_rcf_2_e\n",
            "  ✓ Encoded: i2_rcf_2_place\n",
            "  ✓ Encoded: i2_dep_3_p\n",
            "  ✓ Encoded: i2_dep_3_e\n",
            "  ✓ Encoded: i2_dep_3_place\n",
            "  ✓ Encoded: i2_rcf_3_p\n",
            "  ✓ Encoded: i2_rcf_3_e\n",
            "  ✓ Encoded: i2_rcf_3_place\n",
            "  ✓ Encoded: i2_dlv_p\n",
            "  ✓ Encoded: i2_dlv_e\n",
            "  ✓ Encoded: i2_hops\n",
            "  ✓ Encoded: i3_legid\n",
            "  ✓ Encoded: i3_rcs_p\n",
            "  ✓ Encoded: i3_rcs_e\n",
            "  ✓ Encoded: i3_dep_1_p\n",
            "  ✓ Encoded: i3_dep_1_e\n",
            "  ✓ Encoded: i3_dep_1_place\n",
            "  ✓ Encoded: i3_rcf_1_p\n",
            "  ✓ Encoded: i3_rcf_1_e\n",
            "  ✓ Encoded: i3_rcf_1_place\n",
            "  ✓ Encoded: i3_dep_2_p\n",
            "  ✓ Encoded: i3_dep_2_e\n",
            "  ✓ Encoded: i3_dep_2_place\n",
            "  ✓ Encoded: i3_rcf_2_p\n",
            "  ✓ Encoded: i3_rcf_2_e\n",
            "  ✓ Encoded: i3_rcf_2_place\n",
            "  ✓ Encoded: i3_dep_3_p\n",
            "  ✓ Encoded: i3_dep_3_e\n",
            "  ✓ Encoded: i3_dep_3_place\n",
            "  ✓ Encoded: i3_rcf_3_p\n",
            "  ✓ Encoded: i3_rcf_3_e\n",
            "  ✓ Encoded: i3_rcf_3_place\n",
            "  ✓ Encoded: i3_dlv_p\n",
            "  ✓ Encoded: i3_dlv_e\n",
            "  ✓ Encoded: i3_hops\n",
            "  ✓ Encoded: o_dep_2_p\n",
            "  ✓ Encoded: o_dep_2_e\n",
            "  ✓ Encoded: o_dep_2_place\n",
            "  ✓ Encoded: o_rcf_2_p\n",
            "  ✓ Encoded: o_rcf_2_e\n",
            "  ✓ Encoded: o_rcf_2_place\n",
            "  ✓ Encoded: o_dep_3_p\n",
            "  ✓ Encoded: o_dep_3_e\n",
            "  ✓ Encoded: o_dep_3_place\n",
            "  ✓ Encoded: o_rcf_3_p\n",
            "  ✓ Encoded: o_rcf_3_e\n",
            "  ✓ Encoded: o_rcf_3_place\n",
            "\n",
            "Encoding target column: legs\n",
            "  ✓ Encoded: legs\n",
            "\n",
            "Removed potential leaky columns: {'i3_legid', 'i3_dlv_p', 'i3_rcf_3_e', 'i3_dep_3_place', 'i3_dep_1_p', 'i3_rcf_2_place', 'i3_dep_2_place', 'i3_dep_3_e', 'o_hops', 'i3_rcf_1_p', 'i2_dlv_p', 'i3_rcf_1_e', 'i2_hops', 'i3_dep_2_e', 'i3_rcs_p', 'i3_rcf_3_place', 'nr', 'i3_dep_3_p', 'i3_dlv_e', 'i3_rcf_2_e', 'i3_rcf_3_p', 'i3_rcf_2_p', 'i3_rcs_e', 'i2_dlv_e', 'i3_dep_1_place', 'i3_dep_1_e', 'i1_hops', 'i3_dep_2_p', 'i3_rcf_1_place', 'i3_hops'}\n",
            "New X shape after removing leak: (3942, 67)\n",
            "\n",
            "Imputing remaining NaNs using median strategy...\n",
            "  ✓ Imputation completed.\n",
            "\n",
            "Scaling numerical features...\n",
            "  ✓ Scaling completed.\n",
            "\n",
            "Creating 2nd-degree Polynomial/Interaction Features (Targeted)...\n",
            "  ✓ Added top 200 interaction features.\n",
            "\n",
            "Cleaning up feature names for model compatibility...\n",
            "  ✓ Cleanup completed. Final unique feature count: 252\n",
            "\n",
            "Target variable distribution (Encoded):\n",
            "legs\n",
            "2    1366\n",
            "0    1318\n",
            "1    1258\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✓ Train/test split completed:\n",
            "  X_train shape: (3153, 252)\n",
            "  X_test shape: (789, 252)\n",
            "  y_train shape: (3153,)\n",
            "  y_test shape: (789,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. MODEL DEFINITION (Expanded Search Space)\n",
        "# ==============================================================================\n",
        "\n",
        "# Define a dictionary of models to train\n",
        "models = {\n",
        "    # LOGISTIC REGRESSION (Expanded)\n",
        "    'Logistic_Regression_default': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Logistic_Regression_l1_liblinear': LogisticRegression(random_state=42, penalty='l1', solver='liblinear', max_iter=1000),\n",
        "    'Logistic_Regression_C10': LogisticRegression(random_state=42, C=10, max_iter=1000),\n",
        "    'Logistic_Regression_C01': LogisticRegression(random_state=42, C=0.1, max_iter=1000), # NEW C value\n",
        "    'Logistic_Regression_l2_lbfgs': LogisticRegression(random_state=42, penalty='l2', solver='lbfgs', max_iter=1000), # NEW penalty/solver combo\n",
        "    'Logistic_Regression_C10_l1': LogisticRegression(random_state=42, C=10, penalty='l1', solver='liblinear', max_iter=1000), # NEW combination\n",
        "\n",
        "    # DECISION TREES (Expanded)\n",
        "    'Decision_Tree_default': DecisionTreeClassifier(random_state=42),\n",
        "    'Decision_Tree_depth10': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
        "    'Decision_Tree_min_samples_10': DecisionTreeClassifier(random_state=42, min_samples_leaf=10),\n",
        "    'Decision_Tree_depth5': DecisionTreeClassifier(random_state=42, max_depth=5), # NEW depth\n",
        "    'Decision_Tree_min_samples_5': DecisionTreeClassifier(random_state=42, min_samples_leaf=5), # NEW min_samples_leaf\n",
        "    'Decision_Tree_entropy': DecisionTreeClassifier(random_state=42, criterion='entropy'), # NEW criterion\n",
        "\n",
        "    # RANDOM FOREST (Expanded)\n",
        "    'Random_Forest_default': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    'Random_Forest_150trees': RandomForestClassifier(random_state=42, n_estimators=150),\n",
        "    'Random_Forest_depth10': RandomForestClassifier(random_state=42, max_depth=10),\n",
        "    'Random_Forest_200trees': RandomForestClassifier(random_state=42, n_estimators=200), # NEW n_estimators\n",
        "    'Random_Forest_depth5': RandomForestClassifier(random_state=42, max_depth=5), # NEW max_depth\n",
        "    'Random_Forest_min_samples_5': RandomForestClassifier(random_state=42, min_samples_leaf=5), # NEW min_samples_leaf\n",
        "\n",
        "    # LIGHTGBM (Already good with 3+ hyperparameters and multiple values)\n",
        "    'LightGBM_default': LGBMClassifier(random_state=42, verbose=-1),\n",
        "    'LightGBM_lr01': LGBMClassifier(random_state=42, learning_rate=0.01, verbose=-1),\n",
        "    'LightGBM_depth5': LGBMClassifier(random_state=42, max_depth=5, verbose=-1),\n",
        "    'LightGBM_n500': LGBMClassifier(random_state=42, n_estimators=500, verbose=-1),\n",
        "\n",
        "    # XGBOOST (Expanded)\n",
        "    'XGBoost_default': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    'XGBoost_lr01': XGBClassifier(random_state=42, learning_rate=0.01, use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    'XGBoost_depth5': XGBClassifier(random_state=42, max_depth=5, use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    'XGBoost_n200': XGBClassifier(random_state=42, n_estimators=200, use_label_encoder=False, eval_metric='mlogloss'), # NEW n_estimators\n",
        "    'XGBoost_lr005': XGBClassifier(random_state=42, learning_rate=0.05, use_label_encoder=False, eval_metric='mlogloss'), # NEW learning_rate\n",
        "    'XGBoost_depth3': XGBClassifier(random_state=42, max_depth=3, use_label_encoder=False, eval_metric='mlogloss'), # NEW max_depth\n",
        "\n",
        "    # CATBOOST (Already good with 3+ hyperparameters and multiple values)\n",
        "    'CatBoost_default': CatBoostClassifier(random_state=42, verbose=0),\n",
        "    'CatBoost_lr01': CatBoostClassifier(random_state=42, verbose=0, learning_rate=0.01),\n",
        "    'CatBoost_depth5': CatBoostClassifier(random_state=42, verbose=0, depth=5),\n",
        "    'CatBoost_n500': CatBoostClassifier(random_state=42, verbose=0, n_estimators=500),\n",
        "    'CatBoost_lr005': CatBoostClassifier(random_state=42, verbose=0, learning_rate=0.05),\n",
        "\n",
        "    # NEW MODEL TYPE: MULTILAYER PERCEPTRON (MLP/Neural Network) (Expanded)\n",
        "    'MLP_default': MLPClassifier(random_state=42, max_iter=500, verbose=False),\n",
        "    'MLP_hidden50': MLPClassifier(random_state=42, max_iter=500, hidden_layer_sizes=(50, ), verbose=False),\n",
        "    'MLP_hidden100_50': MLPClassifier(random_state=42, max_iter=500, hidden_layer_sizes=(100, 50), verbose=False), # NEW hidden_layer_sizes\n",
        "    'MLP_tanh': MLPClassifier(random_state=42, max_iter=500, activation='tanh', verbose=False), # NEW activation\n",
        "    'MLP_sgd': MLPClassifier(random_state=42, max_iter=500, solver='sgd', verbose=False), # NEW solver\n",
        "\n",
        "    # NEW MODEL TYPE: SUPPORT VECTOR MACHINE (SVC) (Already good with 3+ hyperparameters and multiple values)\n",
        "    'SVC_rbf_C1': SVC(random_state=42, C=1.0, kernel='rbf', probability=True),\n",
        "    'SVC_linear_C01': SVC(random_state=42, C=0.1, kernel='linear', probability=True),\n",
        "    'SVC_poly_C10': SVC(random_state=42, C=10.0, kernel='poly', degree=3, probability=True),\n",
        "    'SVC_rbf_gamma_auto': SVC(random_state=42, C=1.0, kernel='rbf', gamma='auto', probability=True),\n",
        "    'SVC_linear_C1_gamma_scale': SVC(random_state=42, C=1.0, kernel='linear', gamma='scale', probability=True),\n",
        "\n",
        "    # NEW MODEL TYPE: GAUSSIAN NAIVE BAYES (Main hyperparameter var_smoothing already has multiple values)\n",
        "    'GaussianNB_default': GaussianNB(),\n",
        "    'GaussianNB_var_smooth_1e8': GaussianNB(var_smoothing=1e-8),\n",
        "    'GaussianNB_var_smooth_1e7': GaussianNB(var_smoothing=1e-7),\n",
        "    'GaussianNB_var_smooth_1e6': GaussianNB(var_smoothing=1e-6), # Additional value for var_smoothing\n",
        "\n",
        "    # NEW MODEL TYPE: K-NEAREST NEIGHBORS (Already good with 3+ hyperparameters and multiple values)\n",
        "    'KNeighbors_default': KNeighborsClassifier(n_neighbors=5),\n",
        "    'KNeighbors_n3_uniform': KNeighborsClassifier(n_neighbors=3, weights='uniform'),\n",
        "    'KNeighbors_n10_distance': KNeighborsClassifier(n_neighbors=10, weights='distance'),\n",
        "    'KNeighbors_n5_euclidean': KNeighborsClassifier(n_neighbors=5, metric='euclidean'),\n",
        "    'KNeighbors_n7_manhattan': KNeighborsClassifier(n_neighbors=7, metric='manhattan') # Additional metric\n",
        "}\n",
        "\n",
        "print(f\"Total models defined: {len(models)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxnP-lX5N_x6",
        "outputId": "e209ebe5-e4dd-4352-80e5-8d9cbfc4611a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total models defined: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd # Import pandas for results_df\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np # For np.argsort\n",
        "\n",
        "# ... (Previous model list definitions remain the same) ...\n",
        "\n",
        "# Initialize a DataFrame to store results for comparison\n",
        "results_df = pd.DataFrame(columns=['Model', 'Run_ID', 'Accuracy', 'Precision (Macro)', 'Recall (Macro)', 'F1 (Macro)', 'ROC_AUC (OVR)'])\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n\" + \"=\"*70)\n",
        "    print(f\"Training: {model_name}\")\n",
        "    print(f\"=\"*70)\n",
        "\n",
        "    with mlflow.start_run(run_name=model_name) as run:\n",
        "        print(f\"🔬 MLflow Run Started: {run.info.run_id}\")\n",
        "\n",
        "        try:\n",
        "            # --- Training ---\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # --- Metrics Calculation ---\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "            recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "            f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "            roc_auc = None\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                y_pred_proba = model.predict_proba(X_test)\n",
        "                # Handle cases where y_test might have fewer than 2 unique classes for ROC AUC\n",
        "                if len(np.unique(y_test)) > 1:\n",
        "                    roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "            # --- MLflow Logging (Metrics & Params) ---\n",
        "            mlflow.log_param(\"model_type\", model_name.split('_')[0])\n",
        "            mlflow.log_metric(\"accuracy\", accuracy)\n",
        "            mlflow.log_metric(\"f1_score_macro\", f1)\n",
        "            if roc_auc is not None:\n",
        "                mlflow.log_metric(\"roc_auc_ovr_macro\", roc_auc)\n",
        "\n",
        "            # Log all model parameters\n",
        "            for param_name, param_value in model.get_params().items():\n",
        "                mlflow.log_param(f\"model_{param_name}\", param_value)\n",
        "\n",
        "            # --- ARTIFACT GENERATION & LOGGING ---\n",
        "\n",
        "            # 1. Confusion Matrix Plot\n",
        "            fig_cm, ax = plt.subplots(figsize=(8, 6))\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "            disp.plot(cmap='Blues', ax=ax)\n",
        "            plt.title(f'Confusion Matrix: {model_name}')\n",
        "\n",
        "            # Save locally then log to MLflow\n",
        "            cm_filename = \"confusion_matrix.png\"\n",
        "            plt.savefig(cm_filename)\n",
        "            mlflow.log_artifact(cm_filename) # Uploads to Databricks/MLflow\n",
        "            plt.close(fig_cm)\n",
        "            print(f\"  ✓ Logged artifact: {cm_filename}\")\n",
        "\n",
        "            # 2. Feature Importance Plot (Tree models only)\n",
        "            if hasattr(model, 'feature_importances_'):\n",
        "                fig_fi, ax = plt.subplots(figsize=(10, 6))\n",
        "                importances = model.feature_importances_\n",
        "                indices = np.argsort(importances)[::-1]\n",
        "                # Top 20 features\n",
        "                top_indices = indices[:20]\n",
        "\n",
        "                plt.bar(range(len(top_indices)), importances[top_indices], align='center')\n",
        "                plt.xticks(range(len(top_indices)), [X.columns[i] for i in top_indices], rotation=90)\n",
        "                plt.title(f'Top 20 Feature Importances: {model_name}')\n",
        "                plt.tight_layout()\n",
        "\n",
        "                fi_filename = \"feature_importance.png\"\n",
        "                plt.savefig(fi_filename)\n",
        "                mlflow.log_artifact(fi_filename)\n",
        "                plt.close(fig_fi)\n",
        "                print(f\"  ✓ Logged artifact: {fi_filename}\")\n",
        "\n",
        "            # --- Log Model ---\n",
        "            mlflow.sklearn.log_model(model, name=\"model\", input_example=X_train.head(1))\n",
        "\n",
        "            print(f\"✓ Model logged to Databricks\")\n",
        "\n",
        "            # --- Store results in DataFrame ---\n",
        "            results_df.loc[len(results_df)] = [\n",
        "                model_name,\n",
        "                run.info.run_id,\n",
        "                accuracy,\n",
        "                precision,\n",
        "                recall,\n",
        "                f1,\n",
        "                roc_auc\n",
        "            ]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"!!! FATAL ERROR: Model {model_name} failed. {e}\")\n",
        "\n",
        "# Sort results by F1 Score to find the best model\n",
        "results_df = results_df.sort_values(by='F1 (Macro)', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL MODEL TRAINING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "display(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FGJ8xqKDOCah",
        "outputId": "5006df9a-2b83-451c-e470-be1556fa49fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Training: Logistic_Regression_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 46541d8acee343b8bba06a620ad3eafb\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Logistic_Regression_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/46541d8acee343b8bba06a620ad3eafb\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Logistic_Regression_l1_liblinear\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: f779ecf6fb20498b87976735e289e5c3\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Logistic_Regression_l1_liblinear at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/f779ecf6fb20498b87976735e289e5c3\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Logistic_Regression_C10\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 7fba67b8f75e496eaea6d96a73c01085\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Logistic_Regression_C10 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/7fba67b8f75e496eaea6d96a73c01085\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Logistic_Regression_C01\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: b544572052614503a165384864b3111b\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Logistic_Regression_C01 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/b544572052614503a165384864b3111b\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Logistic_Regression_l2_lbfgs\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: a84e7ce6633b4d04b231008d8afa0ec6\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Logistic_Regression_l2_lbfgs at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/a84e7ce6633b4d04b231008d8afa0ec6\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Logistic_Regression_C10_l1\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 4d3a355d1e4b4efb8c785b6eda992290\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Logistic_Regression_C10_l1 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/4d3a355d1e4b4efb8c785b6eda992290\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Decision_Tree_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 7ff01aae2c90439ab66871ce97610762\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Decision_Tree_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/7ff01aae2c90439ab66871ce97610762\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Decision_Tree_depth10\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 4dff9b8f8f6a4742b50ed7760b049907\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Decision_Tree_depth10 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/4dff9b8f8f6a4742b50ed7760b049907\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Decision_Tree_min_samples_10\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 5e46817d96b24c839653cd0cfc588266\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Decision_Tree_min_samples_10 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/5e46817d96b24c839653cd0cfc588266\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Decision_Tree_depth5\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: f6b9a50c6ac7450db7e595521d3d7ea3\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Decision_Tree_depth5 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/f6b9a50c6ac7450db7e595521d3d7ea3\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Decision_Tree_min_samples_5\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 3dbe4bb7c52f497a96663f770baa6975\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Decision_Tree_min_samples_5 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/3dbe4bb7c52f497a96663f770baa6975\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Decision_Tree_entropy\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: c2699c42cf01453b93da358ee8cd902c\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Decision_Tree_entropy at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/c2699c42cf01453b93da358ee8cd902c\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Random_Forest_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 7db18d60b3bb46dc8b746beff6bc84b9\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Random_Forest_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/7db18d60b3bb46dc8b746beff6bc84b9\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Random_Forest_150trees\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 424675382740420b8ddc87d4bb4962c4\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Random_Forest_150trees at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/424675382740420b8ddc87d4bb4962c4\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Random_Forest_depth10\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: d2acec2cd3d3425dbea255a97d106122\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Random_Forest_depth10 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/d2acec2cd3d3425dbea255a97d106122\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Random_Forest_200trees\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: b785ac60f8154d339f327fa7be5af9e3\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Random_Forest_200trees at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/b785ac60f8154d339f327fa7be5af9e3\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Random_Forest_depth5\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 2492a36223fb4cd4b2517259ccf8eadd\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Random_Forest_depth5 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/2492a36223fb4cd4b2517259ccf8eadd\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: Random_Forest_min_samples_5\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: db8c122191ad48679aa11149ecf7c9c2\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run Random_Forest_min_samples_5 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/db8c122191ad48679aa11149ecf7c9c2\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: LightGBM_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 943f071f0a054367ae30c0254e6cb2af\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run LightGBM_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/943f071f0a054367ae30c0254e6cb2af\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: LightGBM_lr01\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 894fa24b4013491e831ff40ad2b3a229\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run LightGBM_lr01 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/894fa24b4013491e831ff40ad2b3a229\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: LightGBM_depth5\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 703c2b08804e42a8945a153021a8d904\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run LightGBM_depth5 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/703c2b08804e42a8945a153021a8d904\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: LightGBM_n500\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 85effb752d364232851c285927511bbf\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run LightGBM_n500 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/85effb752d364232851c285927511bbf\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: XGBoost_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 7734ee080c584816bacb421ada21b5bf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [22:41:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run XGBoost_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/7734ee080c584816bacb421ada21b5bf\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: XGBoost_lr01\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 05fd8f6d207c438e810349a6855c2b0b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [22:41:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run XGBoost_lr01 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/05fd8f6d207c438e810349a6855c2b0b\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: XGBoost_depth5\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 4910502fb76f4165b03592965c075b80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [22:41:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run XGBoost_depth5 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/4910502fb76f4165b03592965c075b80\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: XGBoost_n200\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 6f99fb81127d40108e23bdc652fb8d53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [22:41:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run XGBoost_n200 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/6f99fb81127d40108e23bdc652fb8d53\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: XGBoost_lr005\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 28eb6546f7e94cdf84f43013a77c2aa7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [22:42:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run XGBoost_lr005 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/28eb6546f7e94cdf84f43013a77c2aa7\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: XGBoost_depth3\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 82421e4dd74b486aa6dca8407fde4b36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [22:42:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run XGBoost_depth3 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/82421e4dd74b486aa6dca8407fde4b36\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: CatBoost_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: ac35cbea4eb14bbcbbe25abac2d1d1bd\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n",
            "✓ Model logged to Databricks\n",
            "🏃 View run CatBoost_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/ac35cbea4eb14bbcbbe25abac2d1d1bd\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: CatBoost_lr01\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: af1a715ff89a4c55946efc2238984625\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n",
            "✓ Model logged to Databricks\n",
            "🏃 View run CatBoost_lr01 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/af1a715ff89a4c55946efc2238984625\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: CatBoost_depth5\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 3ba6c01e2c3e49c8b7814197317fcd92\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n",
            "✓ Model logged to Databricks\n",
            "🏃 View run CatBoost_depth5 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/3ba6c01e2c3e49c8b7814197317fcd92\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: CatBoost_n500\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 2b4b1f67cc514de19d1d338378b196f9\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n",
            "✓ Model logged to Databricks\n",
            "🏃 View run CatBoost_n500 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/2b4b1f67cc514de19d1d338378b196f9\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: CatBoost_lr005\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: b7d00a722f42477e83089bc9ce620eda\n",
            "  ✓ Logged artifact: confusion_matrix.png\n",
            "  ✓ Logged artifact: feature_importance.png\n",
            "✓ Model logged to Databricks\n",
            "🏃 View run CatBoost_lr005 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/b7d00a722f42477e83089bc9ce620eda\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: MLP_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 6a811e7ace00485bb2b32cc814eea91e\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run MLP_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/6a811e7ace00485bb2b32cc814eea91e\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: MLP_hidden50\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 8a1ed1386382482884eb58db9769bb74\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run MLP_hidden50 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/8a1ed1386382482884eb58db9769bb74\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: MLP_hidden100_50\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: f76a86cf55c7418e8ea9c91e942416a0\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run MLP_hidden100_50 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/f76a86cf55c7418e8ea9c91e942416a0\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: MLP_tanh\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: b530d3168d1a4d368b889253e44ef0af\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run MLP_tanh at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/b530d3168d1a4d368b889253e44ef0af\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: MLP_sgd\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 32385eac59a7499abd7913477f171b12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run MLP_sgd at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/32385eac59a7499abd7913477f171b12\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: SVC_rbf_C1\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: cb2e4aeb70474ceea76133d4334c9800\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run SVC_rbf_C1 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/cb2e4aeb70474ceea76133d4334c9800\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: SVC_linear_C01\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 0746fe523029428e92d5cd785fda9b7f\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run SVC_linear_C01 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/0746fe523029428e92d5cd785fda9b7f\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: SVC_poly_C10\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: b3472d7eadd24c3c80e374d64067a8e5\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run SVC_poly_C10 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/b3472d7eadd24c3c80e374d64067a8e5\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: SVC_rbf_gamma_auto\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: a09eb800a5d04b678a53e9fd115fa385\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run SVC_rbf_gamma_auto at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/a09eb800a5d04b678a53e9fd115fa385\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: SVC_linear_C1_gamma_scale\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 8bf9e81ff1614498965a68a268b6a4a6\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run SVC_linear_C1_gamma_scale at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/8bf9e81ff1614498965a68a268b6a4a6\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: GaussianNB_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 510fcc90a79a47b196596e6846386780\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run GaussianNB_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/510fcc90a79a47b196596e6846386780\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: GaussianNB_var_smooth_1e8\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 2c63a5f0295045378cb04659a5f1e00f\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run GaussianNB_var_smooth_1e8 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/2c63a5f0295045378cb04659a5f1e00f\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: GaussianNB_var_smooth_1e7\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 436c7dda28784a739ed920f6f3c2f348\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run GaussianNB_var_smooth_1e7 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/436c7dda28784a739ed920f6f3c2f348\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: GaussianNB_var_smooth_1e6\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 7b9eea29e9824847b5e57b70f73e956b\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run GaussianNB_var_smooth_1e6 at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/7b9eea29e9824847b5e57b70f73e956b\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: KNeighbors_default\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 3beeafb0781b460dbc71e19de16da3ae\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run KNeighbors_default at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/3beeafb0781b460dbc71e19de16da3ae\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: KNeighbors_n3_uniform\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 98ef27dcc5c8414b95d50bfc05b04ea8\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run KNeighbors_n3_uniform at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/98ef27dcc5c8414b95d50bfc05b04ea8\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: KNeighbors_n10_distance\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 90f64054b47e48bcb505de71f7722726\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run KNeighbors_n10_distance at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/90f64054b47e48bcb505de71f7722726\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: KNeighbors_n5_euclidean\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 4149ec9c0942457486407e25cb0d2068\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run KNeighbors_n5_euclidean at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/4149ec9c0942457486407e25cb0d2068\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "Training: KNeighbors_n7_manhattan\n",
            "======================================================================\n",
            "🔬 MLflow Run Started: 49d9c09db90a472c8499bbcce3124acf\n",
            "  ✓ Logged artifact: confusion_matrix.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model logged to Databricks\n",
            "🏃 View run KNeighbors_n7_manhattan at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190/runs/49d9c09db90a472c8499bbcce3124acf\n",
            "🧪 View experiment at: https://dbc-a0c89f71-7936.cloud.databricks.com/ml/experiments/3868354309605190\n",
            "\n",
            "======================================================================\n",
            "ALL MODEL TRAINING COMPLETE\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               Model                            Run_ID  \\\n",
              "0                   CatBoost_default  ac35cbea4eb14bbcbbe25abac2d1d1bd   \n",
              "1                     XGBoost_depth3  82421e4dd74b486aa6dca8407fde4b36   \n",
              "2                    XGBoost_default  7734ee080c584816bacb421ada21b5bf   \n",
              "3                       XGBoost_n200  6f99fb81127d40108e23bdc652fb8d53   \n",
              "4        Random_Forest_min_samples_5  db8c122191ad48679aa11149ecf7c9c2   \n",
              "5                   MLP_hidden100_50  f76a86cf55c7418e8ea9c91e942416a0   \n",
              "6                      LightGBM_n500  85effb752d364232851c285927511bbf   \n",
              "7                     XGBoost_depth5  4910502fb76f4165b03592965c075b80   \n",
              "8                     CatBoost_lr005  b7d00a722f42477e83089bc9ce620eda   \n",
              "9                        MLP_default  6a811e7ace00485bb2b32cc814eea91e   \n",
              "10                     CatBoost_n500  2b4b1f67cc514de19d1d338378b196f9   \n",
              "11             Decision_Tree_entropy  c2699c42cf01453b93da358ee8cd902c   \n",
              "12                     CatBoost_lr01  af1a715ff89a4c55946efc2238984625   \n",
              "13                     LightGBM_lr01  894fa24b4013491e831ff40ad2b3a229   \n",
              "14                      MLP_hidden50  8a1ed1386382482884eb58db9769bb74   \n",
              "15           KNeighbors_n7_manhattan  49d9c09db90a472c8499bbcce3124acf   \n",
              "16                   CatBoost_depth5  3ba6c01e2c3e49c8b7814197317fcd92   \n",
              "17             KNeighbors_n3_uniform  98ef27dcc5c8414b95d50bfc05b04ea8   \n",
              "18                          MLP_tanh  b530d3168d1a4d368b889253e44ef0af   \n",
              "19                  LightGBM_default  943f071f0a054367ae30c0254e6cb2af   \n",
              "20                SVC_rbf_gamma_auto  a09eb800a5d04b678a53e9fd115fa385   \n",
              "21             Random_Forest_default  7db18d60b3bb46dc8b746beff6bc84b9   \n",
              "22                        SVC_rbf_C1  cb2e4aeb70474ceea76133d4334c9800   \n",
              "23                   LightGBM_depth5  703c2b08804e42a8945a153021a8d904   \n",
              "24            Random_Forest_150trees  424675382740420b8ddc87d4bb4962c4   \n",
              "25                     XGBoost_lr005  28eb6546f7e94cdf84f43013a77c2aa7   \n",
              "26           KNeighbors_n5_euclidean  4149ec9c0942457486407e25cb0d2068   \n",
              "27                KNeighbors_default  3beeafb0781b460dbc71e19de16da3ae   \n",
              "28             Random_Forest_depth10  d2acec2cd3d3425dbea255a97d106122   \n",
              "29            Random_Forest_200trees  b785ac60f8154d339f327fa7be5af9e3   \n",
              "30                           MLP_sgd  32385eac59a7499abd7913477f171b12   \n",
              "31                    SVC_linear_C01  0746fe523029428e92d5cd785fda9b7f   \n",
              "32           KNeighbors_n10_distance  90f64054b47e48bcb505de71f7722726   \n",
              "33           Logistic_Regression_C01  b544572052614503a165384864b3111b   \n",
              "34              Random_Forest_depth5  2492a36223fb4cd4b2517259ccf8eadd   \n",
              "35         SVC_linear_C1_gamma_scale  8bf9e81ff1614498965a68a268b6a4a6   \n",
              "36  Logistic_Regression_l1_liblinear  f779ecf6fb20498b87976735e289e5c3   \n",
              "37       Logistic_Regression_default  46541d8acee343b8bba06a620ad3eafb   \n",
              "38      Logistic_Regression_l2_lbfgs  a84e7ce6633b4d04b231008d8afa0ec6   \n",
              "39        Logistic_Regression_C10_l1  4d3a355d1e4b4efb8c785b6eda992290   \n",
              "40                      XGBoost_lr01  05fd8f6d207c438e810349a6855c2b0b   \n",
              "41      Decision_Tree_min_samples_10  5e46817d96b24c839653cd0cfc588266   \n",
              "42             Decision_Tree_default  7ff01aae2c90439ab66871ce97610762   \n",
              "43           Logistic_Regression_C10  7fba67b8f75e496eaea6d96a73c01085   \n",
              "44       Decision_Tree_min_samples_5  3dbe4bb7c52f497a96663f770baa6975   \n",
              "45                      SVC_poly_C10  b3472d7eadd24c3c80e374d64067a8e5   \n",
              "46              Decision_Tree_depth5  f6b9a50c6ac7450db7e595521d3d7ea3   \n",
              "47             Decision_Tree_depth10  4dff9b8f8f6a4742b50ed7760b049907   \n",
              "48                GaussianNB_default  510fcc90a79a47b196596e6846386780   \n",
              "49         GaussianNB_var_smooth_1e6  7b9eea29e9824847b5e57b70f73e956b   \n",
              "50         GaussianNB_var_smooth_1e8  2c63a5f0295045378cb04659a5f1e00f   \n",
              "51         GaussianNB_var_smooth_1e7  436c7dda28784a739ed920f6f3c2f348   \n",
              "\n",
              "    Accuracy  Precision (Macro)  Recall (Macro)  F1 (Macro)  ROC_AUC (OVR)  \n",
              "0   0.708492           0.701521        0.700715    0.700022       0.858032  \n",
              "1   0.703422           0.697021        0.696894    0.696870       0.849691  \n",
              "2   0.699620           0.692292        0.691732    0.691020       0.850156  \n",
              "3   0.698352           0.691346        0.691046    0.690758       0.852041  \n",
              "4   0.697085           0.689416        0.688740    0.687604       0.850341  \n",
              "5   0.693283           0.687090        0.687090    0.687090       0.820398  \n",
              "6   0.694550           0.687277        0.686965    0.686531       0.851666  \n",
              "7   0.693283           0.686525        0.686415    0.686337       0.846429  \n",
              "8   0.692015           0.684456        0.684109    0.683451       0.846646  \n",
              "9   0.684411           0.679747        0.679187    0.679112       0.836052  \n",
              "10  0.686946           0.679399        0.679207    0.678726       0.844607  \n",
              "11  0.684411           0.677976        0.677971    0.677972       0.760699  \n",
              "12  0.693283           0.684310        0.682768    0.677966       0.848640  \n",
              "13  0.689480           0.680685        0.679902    0.677097       0.845874  \n",
              "14  0.683143           0.676873        0.676881    0.676872       0.829169  \n",
              "15  0.683143           0.676350        0.677421    0.676724       0.840455  \n",
              "16  0.683143           0.676123        0.676070    0.675968       0.848609  \n",
              "17  0.683143           0.674467        0.676611    0.675510       0.818659  \n",
              "18  0.680608           0.674289        0.674295    0.674287       0.841613  \n",
              "19  0.680608           0.673903        0.673890    0.673876       0.849214  \n",
              "20  0.688213           0.680408        0.677731    0.673420       0.847082  \n",
              "21  0.680608           0.672897        0.672809    0.672340       0.838955  \n",
              "22  0.686946           0.678194        0.676506    0.672158       0.847000  \n",
              "23  0.679341           0.670505        0.670368    0.668682       0.845165  \n",
              "24  0.676806           0.669029        0.668998    0.668556       0.836931  \n",
              "25  0.678074           0.669098        0.669008    0.667209       0.843162  \n",
              "26  0.674271           0.664247        0.668032    0.666047       0.836228  \n",
              "27  0.674271           0.664247        0.668032    0.666047       0.836228  \n",
              "28  0.681876           0.671373        0.670928    0.665272       0.843845  \n",
              "29  0.671736           0.663062        0.663150    0.662057       0.841383  \n",
              "30  0.666667           0.660422        0.660409    0.660356       0.831148  \n",
              "31  0.670469           0.661041        0.661249    0.659348       0.837197  \n",
              "32  0.666667           0.655021        0.658924    0.656592       0.842417  \n",
              "33  0.666667           0.657434        0.657708    0.656234       0.834540  \n",
              "34  0.692015           0.681584        0.676951    0.654373       0.847481  \n",
              "35  0.664132           0.654769        0.655122    0.653620       0.842253  \n",
              "36  0.662864           0.653347        0.653762    0.652153       0.833211  \n",
              "37  0.661597           0.652634        0.652941    0.651908       0.833622  \n",
              "38  0.661597           0.652634        0.652941    0.651908       0.833622  \n",
              "39  0.660330           0.651045        0.651446    0.650164       0.832127  \n",
              "40  0.673004           0.658693        0.660054    0.648032       0.835069  \n",
              "41  0.653992           0.646300        0.646399    0.646254       0.796690  \n",
              "42  0.651458           0.644647        0.644623    0.644624       0.735883  \n",
              "43  0.653992           0.644893        0.645318    0.644371       0.830508  \n",
              "44  0.646388           0.639480        0.639451    0.639455       0.760502  \n",
              "45  0.676806           0.659204        0.661840    0.639432       0.840972  \n",
              "46  0.690748           0.679499        0.672619    0.628014       0.834052  \n",
              "47  0.633714           0.618303        0.622199    0.616218       0.797871  \n",
              "48  0.662864           0.674565        0.670103    0.609082       0.845366  \n",
              "49  0.662864           0.674565        0.670103    0.609082       0.845366  \n",
              "50  0.662864           0.674565        0.670103    0.609082       0.845366  \n",
              "51  0.662864           0.674565        0.670103    0.609082       0.845366  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f64551f4-ec8e-4911-ae35-eacf0ad8618b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision (Macro)</th>\n",
              "      <th>Recall (Macro)</th>\n",
              "      <th>F1 (Macro)</th>\n",
              "      <th>ROC_AUC (OVR)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CatBoost_default</td>\n",
              "      <td>ac35cbea4eb14bbcbbe25abac2d1d1bd</td>\n",
              "      <td>0.708492</td>\n",
              "      <td>0.701521</td>\n",
              "      <td>0.700715</td>\n",
              "      <td>0.700022</td>\n",
              "      <td>0.858032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost_depth3</td>\n",
              "      <td>82421e4dd74b486aa6dca8407fde4b36</td>\n",
              "      <td>0.703422</td>\n",
              "      <td>0.697021</td>\n",
              "      <td>0.696894</td>\n",
              "      <td>0.696870</td>\n",
              "      <td>0.849691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost_default</td>\n",
              "      <td>7734ee080c584816bacb421ada21b5bf</td>\n",
              "      <td>0.699620</td>\n",
              "      <td>0.692292</td>\n",
              "      <td>0.691732</td>\n",
              "      <td>0.691020</td>\n",
              "      <td>0.850156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XGBoost_n200</td>\n",
              "      <td>6f99fb81127d40108e23bdc652fb8d53</td>\n",
              "      <td>0.698352</td>\n",
              "      <td>0.691346</td>\n",
              "      <td>0.691046</td>\n",
              "      <td>0.690758</td>\n",
              "      <td>0.852041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random_Forest_min_samples_5</td>\n",
              "      <td>db8c122191ad48679aa11149ecf7c9c2</td>\n",
              "      <td>0.697085</td>\n",
              "      <td>0.689416</td>\n",
              "      <td>0.688740</td>\n",
              "      <td>0.687604</td>\n",
              "      <td>0.850341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MLP_hidden100_50</td>\n",
              "      <td>f76a86cf55c7418e8ea9c91e942416a0</td>\n",
              "      <td>0.693283</td>\n",
              "      <td>0.687090</td>\n",
              "      <td>0.687090</td>\n",
              "      <td>0.687090</td>\n",
              "      <td>0.820398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBM_n500</td>\n",
              "      <td>85effb752d364232851c285927511bbf</td>\n",
              "      <td>0.694550</td>\n",
              "      <td>0.687277</td>\n",
              "      <td>0.686965</td>\n",
              "      <td>0.686531</td>\n",
              "      <td>0.851666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>XGBoost_depth5</td>\n",
              "      <td>4910502fb76f4165b03592965c075b80</td>\n",
              "      <td>0.693283</td>\n",
              "      <td>0.686525</td>\n",
              "      <td>0.686415</td>\n",
              "      <td>0.686337</td>\n",
              "      <td>0.846429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CatBoost_lr005</td>\n",
              "      <td>b7d00a722f42477e83089bc9ce620eda</td>\n",
              "      <td>0.692015</td>\n",
              "      <td>0.684456</td>\n",
              "      <td>0.684109</td>\n",
              "      <td>0.683451</td>\n",
              "      <td>0.846646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MLP_default</td>\n",
              "      <td>6a811e7ace00485bb2b32cc814eea91e</td>\n",
              "      <td>0.684411</td>\n",
              "      <td>0.679747</td>\n",
              "      <td>0.679187</td>\n",
              "      <td>0.679112</td>\n",
              "      <td>0.836052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CatBoost_n500</td>\n",
              "      <td>2b4b1f67cc514de19d1d338378b196f9</td>\n",
              "      <td>0.686946</td>\n",
              "      <td>0.679399</td>\n",
              "      <td>0.679207</td>\n",
              "      <td>0.678726</td>\n",
              "      <td>0.844607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Decision_Tree_entropy</td>\n",
              "      <td>c2699c42cf01453b93da358ee8cd902c</td>\n",
              "      <td>0.684411</td>\n",
              "      <td>0.677976</td>\n",
              "      <td>0.677971</td>\n",
              "      <td>0.677972</td>\n",
              "      <td>0.760699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CatBoost_lr01</td>\n",
              "      <td>af1a715ff89a4c55946efc2238984625</td>\n",
              "      <td>0.693283</td>\n",
              "      <td>0.684310</td>\n",
              "      <td>0.682768</td>\n",
              "      <td>0.677966</td>\n",
              "      <td>0.848640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LightGBM_lr01</td>\n",
              "      <td>894fa24b4013491e831ff40ad2b3a229</td>\n",
              "      <td>0.689480</td>\n",
              "      <td>0.680685</td>\n",
              "      <td>0.679902</td>\n",
              "      <td>0.677097</td>\n",
              "      <td>0.845874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>MLP_hidden50</td>\n",
              "      <td>8a1ed1386382482884eb58db9769bb74</td>\n",
              "      <td>0.683143</td>\n",
              "      <td>0.676873</td>\n",
              "      <td>0.676881</td>\n",
              "      <td>0.676872</td>\n",
              "      <td>0.829169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>KNeighbors_n7_manhattan</td>\n",
              "      <td>49d9c09db90a472c8499bbcce3124acf</td>\n",
              "      <td>0.683143</td>\n",
              "      <td>0.676350</td>\n",
              "      <td>0.677421</td>\n",
              "      <td>0.676724</td>\n",
              "      <td>0.840455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>CatBoost_depth5</td>\n",
              "      <td>3ba6c01e2c3e49c8b7814197317fcd92</td>\n",
              "      <td>0.683143</td>\n",
              "      <td>0.676123</td>\n",
              "      <td>0.676070</td>\n",
              "      <td>0.675968</td>\n",
              "      <td>0.848609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>KNeighbors_n3_uniform</td>\n",
              "      <td>98ef27dcc5c8414b95d50bfc05b04ea8</td>\n",
              "      <td>0.683143</td>\n",
              "      <td>0.674467</td>\n",
              "      <td>0.676611</td>\n",
              "      <td>0.675510</td>\n",
              "      <td>0.818659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>MLP_tanh</td>\n",
              "      <td>b530d3168d1a4d368b889253e44ef0af</td>\n",
              "      <td>0.680608</td>\n",
              "      <td>0.674289</td>\n",
              "      <td>0.674295</td>\n",
              "      <td>0.674287</td>\n",
              "      <td>0.841613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LightGBM_default</td>\n",
              "      <td>943f071f0a054367ae30c0254e6cb2af</td>\n",
              "      <td>0.680608</td>\n",
              "      <td>0.673903</td>\n",
              "      <td>0.673890</td>\n",
              "      <td>0.673876</td>\n",
              "      <td>0.849214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>SVC_rbf_gamma_auto</td>\n",
              "      <td>a09eb800a5d04b678a53e9fd115fa385</td>\n",
              "      <td>0.688213</td>\n",
              "      <td>0.680408</td>\n",
              "      <td>0.677731</td>\n",
              "      <td>0.673420</td>\n",
              "      <td>0.847082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Random_Forest_default</td>\n",
              "      <td>7db18d60b3bb46dc8b746beff6bc84b9</td>\n",
              "      <td>0.680608</td>\n",
              "      <td>0.672897</td>\n",
              "      <td>0.672809</td>\n",
              "      <td>0.672340</td>\n",
              "      <td>0.838955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>SVC_rbf_C1</td>\n",
              "      <td>cb2e4aeb70474ceea76133d4334c9800</td>\n",
              "      <td>0.686946</td>\n",
              "      <td>0.678194</td>\n",
              "      <td>0.676506</td>\n",
              "      <td>0.672158</td>\n",
              "      <td>0.847000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>LightGBM_depth5</td>\n",
              "      <td>703c2b08804e42a8945a153021a8d904</td>\n",
              "      <td>0.679341</td>\n",
              "      <td>0.670505</td>\n",
              "      <td>0.670368</td>\n",
              "      <td>0.668682</td>\n",
              "      <td>0.845165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Random_Forest_150trees</td>\n",
              "      <td>424675382740420b8ddc87d4bb4962c4</td>\n",
              "      <td>0.676806</td>\n",
              "      <td>0.669029</td>\n",
              "      <td>0.668998</td>\n",
              "      <td>0.668556</td>\n",
              "      <td>0.836931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>XGBoost_lr005</td>\n",
              "      <td>28eb6546f7e94cdf84f43013a77c2aa7</td>\n",
              "      <td>0.678074</td>\n",
              "      <td>0.669098</td>\n",
              "      <td>0.669008</td>\n",
              "      <td>0.667209</td>\n",
              "      <td>0.843162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>KNeighbors_n5_euclidean</td>\n",
              "      <td>4149ec9c0942457486407e25cb0d2068</td>\n",
              "      <td>0.674271</td>\n",
              "      <td>0.664247</td>\n",
              "      <td>0.668032</td>\n",
              "      <td>0.666047</td>\n",
              "      <td>0.836228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>KNeighbors_default</td>\n",
              "      <td>3beeafb0781b460dbc71e19de16da3ae</td>\n",
              "      <td>0.674271</td>\n",
              "      <td>0.664247</td>\n",
              "      <td>0.668032</td>\n",
              "      <td>0.666047</td>\n",
              "      <td>0.836228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Random_Forest_depth10</td>\n",
              "      <td>d2acec2cd3d3425dbea255a97d106122</td>\n",
              "      <td>0.681876</td>\n",
              "      <td>0.671373</td>\n",
              "      <td>0.670928</td>\n",
              "      <td>0.665272</td>\n",
              "      <td>0.843845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Random_Forest_200trees</td>\n",
              "      <td>b785ac60f8154d339f327fa7be5af9e3</td>\n",
              "      <td>0.671736</td>\n",
              "      <td>0.663062</td>\n",
              "      <td>0.663150</td>\n",
              "      <td>0.662057</td>\n",
              "      <td>0.841383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>MLP_sgd</td>\n",
              "      <td>32385eac59a7499abd7913477f171b12</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.660422</td>\n",
              "      <td>0.660409</td>\n",
              "      <td>0.660356</td>\n",
              "      <td>0.831148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>SVC_linear_C01</td>\n",
              "      <td>0746fe523029428e92d5cd785fda9b7f</td>\n",
              "      <td>0.670469</td>\n",
              "      <td>0.661041</td>\n",
              "      <td>0.661249</td>\n",
              "      <td>0.659348</td>\n",
              "      <td>0.837197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>KNeighbors_n10_distance</td>\n",
              "      <td>90f64054b47e48bcb505de71f7722726</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.655021</td>\n",
              "      <td>0.658924</td>\n",
              "      <td>0.656592</td>\n",
              "      <td>0.842417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Logistic_Regression_C01</td>\n",
              "      <td>b544572052614503a165384864b3111b</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.657434</td>\n",
              "      <td>0.657708</td>\n",
              "      <td>0.656234</td>\n",
              "      <td>0.834540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Random_Forest_depth5</td>\n",
              "      <td>2492a36223fb4cd4b2517259ccf8eadd</td>\n",
              "      <td>0.692015</td>\n",
              "      <td>0.681584</td>\n",
              "      <td>0.676951</td>\n",
              "      <td>0.654373</td>\n",
              "      <td>0.847481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>SVC_linear_C1_gamma_scale</td>\n",
              "      <td>8bf9e81ff1614498965a68a268b6a4a6</td>\n",
              "      <td>0.664132</td>\n",
              "      <td>0.654769</td>\n",
              "      <td>0.655122</td>\n",
              "      <td>0.653620</td>\n",
              "      <td>0.842253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Logistic_Regression_l1_liblinear</td>\n",
              "      <td>f779ecf6fb20498b87976735e289e5c3</td>\n",
              "      <td>0.662864</td>\n",
              "      <td>0.653347</td>\n",
              "      <td>0.653762</td>\n",
              "      <td>0.652153</td>\n",
              "      <td>0.833211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Logistic_Regression_default</td>\n",
              "      <td>46541d8acee343b8bba06a620ad3eafb</td>\n",
              "      <td>0.661597</td>\n",
              "      <td>0.652634</td>\n",
              "      <td>0.652941</td>\n",
              "      <td>0.651908</td>\n",
              "      <td>0.833622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Logistic_Regression_l2_lbfgs</td>\n",
              "      <td>a84e7ce6633b4d04b231008d8afa0ec6</td>\n",
              "      <td>0.661597</td>\n",
              "      <td>0.652634</td>\n",
              "      <td>0.652941</td>\n",
              "      <td>0.651908</td>\n",
              "      <td>0.833622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Logistic_Regression_C10_l1</td>\n",
              "      <td>4d3a355d1e4b4efb8c785b6eda992290</td>\n",
              "      <td>0.660330</td>\n",
              "      <td>0.651045</td>\n",
              "      <td>0.651446</td>\n",
              "      <td>0.650164</td>\n",
              "      <td>0.832127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>XGBoost_lr01</td>\n",
              "      <td>05fd8f6d207c438e810349a6855c2b0b</td>\n",
              "      <td>0.673004</td>\n",
              "      <td>0.658693</td>\n",
              "      <td>0.660054</td>\n",
              "      <td>0.648032</td>\n",
              "      <td>0.835069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Decision_Tree_min_samples_10</td>\n",
              "      <td>5e46817d96b24c839653cd0cfc588266</td>\n",
              "      <td>0.653992</td>\n",
              "      <td>0.646300</td>\n",
              "      <td>0.646399</td>\n",
              "      <td>0.646254</td>\n",
              "      <td>0.796690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Decision_Tree_default</td>\n",
              "      <td>7ff01aae2c90439ab66871ce97610762</td>\n",
              "      <td>0.651458</td>\n",
              "      <td>0.644647</td>\n",
              "      <td>0.644623</td>\n",
              "      <td>0.644624</td>\n",
              "      <td>0.735883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Logistic_Regression_C10</td>\n",
              "      <td>7fba67b8f75e496eaea6d96a73c01085</td>\n",
              "      <td>0.653992</td>\n",
              "      <td>0.644893</td>\n",
              "      <td>0.645318</td>\n",
              "      <td>0.644371</td>\n",
              "      <td>0.830508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Decision_Tree_min_samples_5</td>\n",
              "      <td>3dbe4bb7c52f497a96663f770baa6975</td>\n",
              "      <td>0.646388</td>\n",
              "      <td>0.639480</td>\n",
              "      <td>0.639451</td>\n",
              "      <td>0.639455</td>\n",
              "      <td>0.760502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>SVC_poly_C10</td>\n",
              "      <td>b3472d7eadd24c3c80e374d64067a8e5</td>\n",
              "      <td>0.676806</td>\n",
              "      <td>0.659204</td>\n",
              "      <td>0.661840</td>\n",
              "      <td>0.639432</td>\n",
              "      <td>0.840972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Decision_Tree_depth5</td>\n",
              "      <td>f6b9a50c6ac7450db7e595521d3d7ea3</td>\n",
              "      <td>0.690748</td>\n",
              "      <td>0.679499</td>\n",
              "      <td>0.672619</td>\n",
              "      <td>0.628014</td>\n",
              "      <td>0.834052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Decision_Tree_depth10</td>\n",
              "      <td>4dff9b8f8f6a4742b50ed7760b049907</td>\n",
              "      <td>0.633714</td>\n",
              "      <td>0.618303</td>\n",
              "      <td>0.622199</td>\n",
              "      <td>0.616218</td>\n",
              "      <td>0.797871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>GaussianNB_default</td>\n",
              "      <td>510fcc90a79a47b196596e6846386780</td>\n",
              "      <td>0.662864</td>\n",
              "      <td>0.674565</td>\n",
              "      <td>0.670103</td>\n",
              "      <td>0.609082</td>\n",
              "      <td>0.845366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>GaussianNB_var_smooth_1e6</td>\n",
              "      <td>7b9eea29e9824847b5e57b70f73e956b</td>\n",
              "      <td>0.662864</td>\n",
              "      <td>0.674565</td>\n",
              "      <td>0.670103</td>\n",
              "      <td>0.609082</td>\n",
              "      <td>0.845366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>GaussianNB_var_smooth_1e8</td>\n",
              "      <td>2c63a5f0295045378cb04659a5f1e00f</td>\n",
              "      <td>0.662864</td>\n",
              "      <td>0.674565</td>\n",
              "      <td>0.670103</td>\n",
              "      <td>0.609082</td>\n",
              "      <td>0.845366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>GaussianNB_var_smooth_1e7</td>\n",
              "      <td>436c7dda28784a739ed920f6f3c2f348</td>\n",
              "      <td>0.662864</td>\n",
              "      <td>0.674565</td>\n",
              "      <td>0.670103</td>\n",
              "      <td>0.609082</td>\n",
              "      <td>0.845366</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f64551f4-ec8e-4911-ae35-eacf0ad8618b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f64551f4-ec8e-4911-ae35-eacf0ad8618b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f64551f4-ec8e-4911-ae35-eacf0ad8618b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4a30c308-c31f-46ef-9dd8-054653f1ad0c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a30c308-c31f-46ef-9dd8-054653f1ad0c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4a30c308-c31f-46ef-9dd8-054653f1ad0c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5e7128aa-8097-40bb-b2a8-c79d3dc1e4cf\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5e7128aa-8097-40bb-b2a8-c79d3dc1e4cf button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 52,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 52,\n        \"samples\": [\n          \"LightGBM_default\",\n          \"Decision_Tree_min_samples_10\",\n          \"Decision_Tree_depth10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Run_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 52,\n        \"samples\": [\n          \"943f071f0a054367ae30c0254e6cb2af\",\n          \"5e46817d96b24c839653cd0cfc588266\",\n          \"4dff9b8f8f6a4742b50ed7760b049907\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01563922011214792,\n        \"min\": 0.6337135614702155,\n        \"max\": 0.7084917617237009,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.6463878326996197,\n          0.6768060836501901,\n          0.6615969581749049\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision (Macro)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016081546664508888,\n        \"min\": 0.6183030856943901,\n        \"max\": 0.7015207373271889,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.671373172914388,\n          0.6462995355570299,\n          0.664247046918172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall (Macro)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01531332045260863,\n        \"min\": 0.6221988795518207,\n        \"max\": 0.7007152861144457,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.6709283713485394,\n          0.6463985594237694,\n          0.6680322128851541\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 (Macro)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02315935690265355,\n        \"min\": 0.6090815027061446,\n        \"max\": 0.7000222000222,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.665272473783112,\n          0.6462538487854944,\n          0.6660467598909655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC_AUC (OVR)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02364900201004086,\n        \"min\": 0.7358829581155479,\n        \"max\": 0.8580322361052738,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.8438445300750862,\n          0.7966900541647993,\n          0.8362284347975167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 7. LOG BEST MODEL SUMMARY\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BEST MODEL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if 'results_df' in locals() and not results_df.empty:\n",
        "    best_model_name = results_df.iloc[0]['Model']\n",
        "    best_run_id = results_df.iloc[0]['Run_ID']\n",
        "    best_f1 = results_df.iloc[0]['F1 (Macro)']\n",
        "    best_accuracy = results_df.iloc[0]['Accuracy']\n",
        "    best_precision = results_df.iloc[0]['Precision (Macro)']\n",
        "    best_recall = results_df.iloc[0]['Recall (Macro)']\n",
        "    best_roc_auc = results_df.iloc[0]['ROC_AUC (OVR)']\n",
        "\n",
        "    print(f\"\\n🏆 Best Model: {best_model_name}\")\n",
        "    print(f\"   Run ID: {best_run_id}\")\n",
        "    print(f\"   F1 Score: {best_f1:.4f}\")\n",
        "    print(f\"   Accuracy: {best_accuracy:.4f}\")\n",
        "    print(f\"   Precision: {best_precision:.4f}\")\n",
        "    print(f\"   Recall: {best_recall:.4f}\")\n",
        "    print(f\"   ROC AUC: {best_roc_auc if best_roc_auc is not None else 'N/A'}\")\n",
        "else:\n",
        "    print(\"\\n--- Best model summary skipped because no models were trained or results_df is empty. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChjO4-JCOFPY",
        "outputId": "5b5b96e9-81dd-46a0-b107-dce73cee2baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "BEST MODEL SUMMARY\n",
            "======================================================================\n",
            "\n",
            "🏆 Best Model: CatBoost_default\n",
            "   Run ID: ac35cbea4eb14bbcbbe25abac2d1d1bd\n",
            "   F1 Score: 0.7000\n",
            "   Accuracy: 0.7085\n",
            "   Precision: 0.7015\n",
            "   Recall: 0.7007\n",
            "   ROC AUC: 0.8580322361052738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 8. TRAINING COMPLETE\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE! 🎉\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if 'results_df' in locals() and not results_df.empty:\n",
        "    print(f\"\\n📊 SUMMARY:\")\n",
        "    print(f\"   Total models trained: {len(models)}\")\n",
        "    print(f\"   All models logged to Databricks MLflow\")\n",
        "    print(f\"   Best model: {best_model_name}\")\n",
        "    print(f\"   Best F1 Score: {best_f1:.4f}\")\n",
        "\n",
        "    print(f\"\\n📊 WHAT WAS LOGGED TO DATABRICKS:\")\n",
        "    print(f\"   ✓ {len(models)} separate MLflow runs\")\n",
        "    print(f\"   ✓ All hyperparameters for each model\")\n",
        "    print(f\"   ✓ All metrics (accuracy, precision, recall, F1, ROC AUC)\")\n",
        "    print(f\"   ✓ All trained models\")\n",
        "\n",
        "    print(f\"\\n🔍 VIEW YOUR EXPERIMENTS IN DATABRICKS:\")\n",
        "    print(f\"   1. Go to your Databricks workspace: {DATABRICKS_HOST}\")\n",
        "    print(f\"   2. Click 'Machine Learning' in left sidebar\")\n",
        "    print(f\"   3. Click 'Experiments'\")\n",
        "    print(f\"   4. Find: {EXPERIMENT_NAME}\")\n",
        "    print(f\"   5. Compare all {len(models)} runs side-by-side\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "else:\n",
        "    print(\"\\n--- Training completion summary skipped. Please check if models were trained and results_df is populated. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUodMen2OH_t",
        "outputId": "e5a0a8ff-11d3-4b36-dde3-e873c0e846ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE! 🎉\n",
            "======================================================================\n",
            "\n",
            "📊 SUMMARY:\n",
            "   Total models trained: 52\n",
            "   All models logged to Databricks MLflow\n",
            "   Best model: CatBoost_default\n",
            "   Best F1 Score: 0.7000\n",
            "\n",
            "📊 WHAT WAS LOGGED TO DATABRICKS:\n",
            "   ✓ 52 separate MLflow runs\n",
            "   ✓ All hyperparameters for each model\n",
            "   ✓ All metrics (accuracy, precision, recall, F1, ROC AUC)\n",
            "   ✓ All trained models\n",
            "\n",
            "🔍 VIEW YOUR EXPERIMENTS IN DATABRICKS:\n",
            "   1. Go to your Databricks workspace: https://dbc-a0c89f71-7936.cloud.databricks.com\n",
            "   2. Click 'Machine Learning' in left sidebar\n",
            "   3. Click 'Experiments'\n",
            "   4. Find: /Users/svemulak@asu.edu/Attempt_6_Supply-Chain-Classification-Experiment-1\n",
            "   5. Compare all 52 runs side-by-side\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1egfrmSGMQ1",
        "outputId": "b2c8d9d5-ca13-43ca-caee-1241fa5fa51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nr', 'i1_legid', 'i1_rcs_p', 'i1_rcs_e', 'i1_dep_1_p', 'i1_dep_1_e', 'i1_dep_1_place', 'i1_rcf_1_p', 'i1_rcf_1_e', 'i1_rcf_1_place', 'i1_dep_2_p', 'i1_dep_2_e', 'i1_dep_2_place', 'i1_rcf_2_p', 'i1_rcf_2_e', 'i1_rcf_2_place', 'i1_dep_3_p', 'i1_dep_3_e', 'i1_dep_3_place', 'i1_rcf_3_p', 'i1_rcf_3_e', 'i1_rcf_3_place', 'i1_dlv_p', 'i1_dlv_e', 'i1_hops', 'i2_legid', 'i2_rcs_p', 'i2_rcs_e', 'i2_dep_1_p', 'i2_dep_1_e', 'i2_dep_1_place', 'i2_rcf_1_p', 'i2_rcf_1_e', 'i2_rcf_1_place', 'i2_dep_2_p', 'i2_dep_2_e', 'i2_dep_2_place', 'i2_rcf_2_p', 'i2_rcf_2_e', 'i2_rcf_2_place', 'i2_dep_3_p', 'i2_dep_3_e', 'i2_dep_3_place', 'i2_rcf_3_p', 'i2_rcf_3_e', 'i2_rcf_3_place', 'i2_dlv_p', 'i2_dlv_e', 'i2_hops', 'i3_legid', 'i3_rcs_p', 'i3_rcs_e', 'i3_dep_1_p', 'i3_dep_1_e', 'i3_dep_1_place', 'i3_rcf_1_p', 'i3_rcf_1_e', 'i3_rcf_1_place', 'i3_dep_2_p', 'i3_dep_2_e', 'i3_dep_2_place', 'i3_rcf_2_p', 'i3_rcf_2_e', 'i3_rcf_2_place', 'i3_dep_3_p', 'i3_dep_3_e', 'i3_dep_3_place', 'i3_rcf_3_p', 'i3_rcf_3_e', 'i3_rcf_3_place', 'i3_dlv_p', 'i3_dlv_e', 'i3_hops', 'o_legid', 'o_rcs_p', 'o_rcs_e', 'o_dep_1_p', 'o_dep_1_e', 'o_dep_1_place', 'o_rcf_1_p', 'o_rcf_1_e', 'o_rcf_1_place', 'o_dep_2_p', 'o_dep_2_e', 'o_dep_2_place', 'o_rcf_2_p', 'o_rcf_2_e', 'o_rcf_2_place', 'o_dep_3_p', 'o_dep_3_e', 'o_dep_3_place', 'o_rcf_3_p', 'o_rcf_3_e', 'o_rcf_3_place', 'o_dlv_p', 'o_dlv_e', 'o_hops', 'legs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "id": "vsUDZjAhGPBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7a0dd4-b3ad-409e-eb7c-d156baed6f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3942, 98)\n"
          ]
        }
      ]
    }
  ]
}